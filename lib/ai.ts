import { GoogleGenerativeAI } from "@google/generative-ai";

const genAI = new GoogleGenerativeAI(process.env.GOOGLE_GEMINI_API_KEY || "");

export async function generateAIResponse(message: string, context: any = {}) {
  if (!process.env.GOOGLE_GEMINI_API_KEY) {
    console.error("CRITICAL: GOOGLE_GEMINI_API_KEY is missing from environment variables");
    return {
      text: "ğŸ¤– Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø¯Ø¹Ù… Ø§Ù„Ø°ÙƒÙŠ: Ø¹Ø°Ø±Ø§Ù‹ØŒ Ù„Ù… ÙŠØªÙ… ØªÙƒÙˆÙŠÙ† Ù…ÙØªØ§Ø­ Ø§Ù„Ù€ AI Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­. ÙŠØ±Ø¬Ù‰ Ø§Ù„ØªÙˆØ§ØµÙ„ Ù…Ø¹ Ø§Ù„Ù…Ø¯ÙŠØ±.",
      confidence: 0
    };
  }

  try {
    const model = genAI.getGenerativeModel({ 
      model: "gemini-1.5-flash",
      generationConfig: {
        maxOutputTokens: 1000,
        temperature: 0.7,
      }
    });

    const systemPrompt = `
Ø£Ù†Øª "Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø¯Ø¹Ù… Ø§Ù„Ø°ÙƒÙŠ" ÙÙŠ Ù†Ø¸Ø§Ù… Logistics Systems Pro.
ÙŠØ¬Ø¨ Ø£Ù† ØªØ¨Ø¯Ø£ Ø±Ø¯Ùƒ Ø¯Ø§Ø¦Ù…Ø§Ù‹ Ø¨Ø¹Ø¨Ø§Ø±Ø© "ğŸ¤– Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø¯Ø¹Ù… Ø§Ù„Ø°ÙƒÙŠ:" Ù„ÙŠØ¹Ø±Ù Ø§Ù„Ø¹Ù…ÙŠÙ„ Ø£Ù†Ù‡ ÙŠØªØ­Ø¯Ø« Ù…Ø¹ Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ.

Ù…Ù‡Ù…ØªÙƒ:
1. ÙÙ‡Ù… Ù…Ø´ÙƒÙ„Ø© Ø§Ù„Ø¹Ù…ÙŠÙ„ Ø¨Ø¯Ù‚Ø©.
2. Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù…Ø²ÙˆØ¯Ø© Ù„Ùƒ Ø£Ø¯Ù†Ø§Ù‡ ÙˆØ§Ù„Ø±Ø¯ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„ÙŠÙ‡Ø§ ÙÙ‚Ø·.
3. Ø¥Ø°Ø§ ÙˆØ¬Ø¯Øª Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ©ØŒ Ù‚Ø¯Ù… Ø­Ù„Ø§Ù‹ Ø®Ø·ÙˆØ© Ø¨Ø®Ø·ÙˆØ©.
4. Ø¥Ø°Ø§ Ù„Ù… ØªØ¬Ø¯ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø£Ùˆ ÙƒØ§Ù†Øª Ø§Ù„Ù…Ø´ÙƒÙ„Ø© Ù…Ø¹Ù‚Ø¯Ø© (Ù…Ø«Ù„ Ù…Ø´Ø§ÙƒÙ„ Ø¨Ø±Ù…Ø¬ÙŠØ© Ø¹Ù…ÙŠÙ‚Ø© Ø£Ùˆ Ø·Ù„Ø¨Ø§Øª Ù…Ø§Ù„ÙŠØ© Ø­Ø³Ø§Ø³Ø©)ØŒ Ù‚Ù„ Ù„Ù„Ø¹Ù…ÙŠÙ„: "Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø³Ø£Ù‚ÙˆÙ… Ø¨ØªØ­ÙˆÙŠÙ„Ùƒ Ù„Ù…Ù…Ø«Ù„ Ø¨Ø´Ø±ÙŠ Ù„Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ Ø¨Ø´ÙƒÙ„ Ø£ÙØ¶Ù„ ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø´ÙƒÙ„Ø© Ø§Ù„Ù…Ø¹Ù‚Ø¯Ø©".
5. Ù„Ø§ ØªØ®ØªÙ„Ù‚ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø£Ø¨Ø¯Ø§Ù‹.

Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯:
- ØªØ­Ø¯Ø« Ø¨Ù†ÙØ³ Ù„ØºØ© Ø§Ù„Ø¹Ù…ÙŠÙ„ (Ø¹Ø±Ø¨ÙŠ ØºØ§Ù„Ø¨Ø§Ù‹).
- ÙƒÙ† Ù…Ù‡Ù†ÙŠØ§Ù‹ØŒ ÙˆØ¯ÙˆØ¯Ø§Ù‹ØŒ ÙˆÙ…Ø®ØªØµØ±Ø§Ù‹.
- Ø§Ø³Ø£Ù„ Ø£Ø³Ø¦Ù„Ø© ØªÙˆØ¶ÙŠØ­ÙŠØ© Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ø¹Ù…ÙŠÙ„ ØºÙŠØ± ÙˆØ§Ø¶Ø­Ø©.

Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¹Ù† Ø§Ù„Ù†Ø¸Ø§Ù…:
- Ø§Ù„Ø§Ø³Ù…: Logistics Systems Pro.
- Ø§Ù„ØªØ®ØµØµ: Ù†Ø¸Ø§Ù… Ø¥Ø¯Ø§Ø±Ø© Ù„ÙˆØ¬Ø³ØªÙŠØ§ØªØŒ Ù…Ø­Ø§Ø³Ø¨Ø©ØŒ Ø´Ø­Ù†ØŒ ÙˆÙ…ÙˆØ§Ø±Ø¯ Ø¨Ø´Ø±ÙŠØ©.

Ø³ÙŠØ§Ù‚ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù…ØªØ§Ø­ Ø­Ø§Ù„ÙŠØ§Ù‹:
${JSON.stringify(context.knowledge_base || [], null, 2)}

ØªØ§Ø±ÙŠØ® Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø£Ø®ÙŠØ±:
${JSON.stringify(context.conversation_history || [], null, 2)}
`;

    let result;
    try {
      result = await model.generateContent([systemPrompt, message]);
    } catch (genError: any) {
      console.error("Primary model failed, trying fallback...", genError.message);
      const fallbackModel = genAI.getGenerativeModel({ model: "gemini-1.5-pro" });
      result = await fallbackModel.generateContent([systemPrompt, message]);
    }

    const response = await result.response;
    let text = response.text().trim();

    if (!text.includes("Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø¯Ø¹Ù… Ø§Ù„Ø°ÙƒÙŠ")) {
      text = "ğŸ¤– Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø¯Ø¹Ù… Ø§Ù„Ø°ÙƒÙŠ: " + text;
    }

    let confidence = 0.9;
    if (text.includes("ØªØ­ÙˆÙŠÙ„Ùƒ Ù„Ù…Ù…Ø«Ù„ Ø¨Ø´Ø±ÙŠ") || text.includes("Ù„Ø§ Ø£Ù…Ù„Ùƒ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª") || text.includes("ØºÙŠØ± Ù…ØªØ£ÙƒØ¯")) {
      confidence = 0.4;
    }

    return { text, confidence };
  } catch (error: any) {
    console.error("Gemini API Error Details:", error.message);
    return {
      text: "ğŸ¤– Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø¯Ø¹Ù… Ø§Ù„Ø°ÙƒÙŠ: Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø£ÙˆØ§Ø¬Ù‡ ØµØ¹ÙˆØ¨Ø© ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø·Ù„Ø¨Ùƒ Ø­Ø§Ù„ÙŠØ§Ù‹. Ø³Ø£Ù‚ÙˆÙ… Ø¨ØªØ­ÙˆÙŠÙ„Ùƒ Ù„Ù…Ù…Ø«Ù„ Ø¨Ø´Ø±ÙŠ ÙÙˆØ±Ø§Ù‹ Ù„Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ.",
      confidence: 0
    };
  }
}

export async function analyzeMessage(message: string) {
  try {
    const model = genAI.getGenerativeModel({ model: "gemini-1.5-flash" });
    const prompt = `
Ø­Ù„Ù„ Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ø¹Ù…ÙŠÙ„ Ø§Ù„ØªØ§Ù„ÙŠØ© ÙˆØ£Ø¬Ø¨ Ø¨ØªÙ†Ø³ÙŠÙ‚ JSON ÙÙ‚Ø·:
{
  "language": "ar" Ø£Ùˆ "en",
  "category": "technical" Ø£Ùˆ "financial" Ø£Ùˆ "service" Ø£Ùˆ "general",
  "urgency": "normal" Ø£Ùˆ "urgent" Ø£Ùˆ "critical",
  "request_human": true Ø¥Ø°Ø§ Ø·Ù„Ø¨ ØµØ±Ø§Ø­Ø© Ù…ÙˆØ¸Ù Ø£Ùˆ Ø¥Ù†Ø³Ø§Ù†ØŒ ÙˆØ¥Ù„Ø§ false
}

Ø§Ù„Ø±Ø³Ø§Ù„Ø©: "${message}"
`;

    let result;
    try {
      result = await model.generateContent(prompt);
    } catch (genError: any) {
      console.error("Analysis Primary model failed, trying fallback...", genError.message);
      const fallbackModel = genAI.getGenerativeModel({ model: "gemini-1.5-pro" });
      result = await fallbackModel.generateContent(prompt);
    }
    
    const response = await result.response;
    const text = response.text();
    
    const jsonMatch = text.match(/\{[\s\S]*\}/);
    const jsonStr = jsonMatch ? jsonMatch[0] : text;
    return JSON.parse(jsonStr);
  } catch (error) {
    console.error("Analysis Error:", error);
    return {
      language: "ar",
      category: "general",
      urgency: "normal",
      request_human: false
    };
  }
}
